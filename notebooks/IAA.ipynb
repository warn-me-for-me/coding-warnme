{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from utils.code_part_utils import calculate_fleiss_kapp, group_columns_by_annotator, get_codes, select_highest_agreement_code\n",
    "\n",
    "\n",
    "# Open 100 codes for IAA\n",
    "data_path = Path.cwd().parent / 'data' / 'warnme-codeparty-IAA.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.rename(columns={\"Unnamed: 0\": \"\"}).set_index(\"\")\n",
    "\n",
    "# Open all codes for final \n",
    "d2_path = Path.cwd().parent / 'data' / 'warnme-codeparty-IAA.csv'\n",
    "df2 = pd.read_csv(d2_path)\n",
    "df2 = df2.rename(columns={\"Unnamed: 0\": \"\"}).set_index(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- https://surge-ai.medium.com/inter-annotator-agreement-an-introduction-to-cohens-kappa-statistic-dcc15ffa5ac4\n",
    "- https://audhiaprilliant.medium.com/cohens-kappa-and-fleiss-kappa-how-to-measure-the-agreement-between-raters-9ec12edef121\n",
    "- Kraemer, H. C. (1980). Extension of the kappa coefficient. Biometrics, 36(2), 207â€“16.\n",
    "\n",
    "# TODO \n",
    "- Correctly import functions (play with import file path)\n",
    "- Confirm functions work and remove from this nb (utils only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fleiss_kappa(df, columns):\n",
    "    \"\"\"\n",
    "    Calculate Fleiss' kappa for the given set of columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    columns (list): A list of column names representing the annotators.\n",
    "    none (bool): Include 'none' codes or not\n",
    "\n",
    "    Returns:\n",
    "    float: The Fleiss' kappa value.\n",
    "    \"\"\"\n",
    "    # Group columns by annotator\n",
    "    grouped_columns = group_columns_by_annotator(columns)\n",
    "\n",
    "    # Get list of all possible codes\n",
    "    codes = get_codes(df, columns)\n",
    "\n",
    "    # Calculate the total number of items (documents/annotations)\n",
    "    total_items = df.shape[0]\n",
    "\n",
    "    # Initialize concordant_pairs\n",
    "    concordant_pairs = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        row_values = []\n",
    "        for annotator_columns in grouped_columns.values():\n",
    "            annotator_values = row[annotator_columns].dropna().unique()\n",
    "            if len(annotator_values) > 0:\n",
    "                row_values.append(annotator_values[0])  # Take the first value for the annotator\n",
    "\n",
    "        if len(row_values) > 1:\n",
    "            # Generate all unique pairs of annotator ratings\n",
    "            pairs = itertools.combinations(row_values, 2)\n",
    "\n",
    "            # Count the number of pairs that agree\n",
    "            concordant_pairs += sum(pair[0] == pair[1] for pair in pairs)\n",
    "\n",
    "    # Calculate the total number of annotator pairs\n",
    "    total_pairs = total_items * (len(grouped_columns) * (len(grouped_columns) - 1)) / 2\n",
    "    value_counts = pd.concat([df[col] for col in columns]).value_counts(normalize=True)\n",
    "\n",
    "    # Calculate the marginal probabilities pj\n",
    "    pj = [value_counts.get(code, 0) for code in codes]\n",
    "\n",
    "    # Calculate the expected proportion of concordant pairs due to chance\n",
    "    pe = sum([p ** 2 for p in pj])\n",
    "\n",
    "    # Calculate the proportion of concordant pairs\n",
    "    pbar = concordant_pairs / total_pairs\n",
    "\n",
    "    # Calculate the Fleiss' kappa\n",
    "    kappa = (pbar - pe) / (1 - pe)\n",
    "\n",
    "    return kappa\n",
    "\n",
    "def group_columns_by_annotator(columns):\n",
    "    \"\"\"\n",
    "    Group columns by annotator, considering columns with the same suffix as the same annotator.\n",
    "\n",
    "    Parameters:\n",
    "    columns (list): A list of column names representing the annotators.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are annotator suffixes, and the values are lists of column names for that annotator.\n",
    "    \"\"\"\n",
    "    grouped_columns = {}\n",
    "    for col in columns:\n",
    "        suffix = col.split('_')[-1]  # Assuming the suffix is the part after the last underscore\n",
    "        if suffix not in grouped_columns:\n",
    "            grouped_columns[suffix] = []\n",
    "        grouped_columns[suffix].append(col)\n",
    "    return grouped_columns\n",
    "\n",
    "def get_codes(df, columns):\n",
    "    \"\"\"\n",
    "    Get unique values across multiple columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    columns (list): A list of column names to get unique values from.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1D array of unique values across the specified columns.\n",
    "    \"\"\"\n",
    "    unique_values = []\n",
    "    for col in columns:\n",
    "        unique_values.extend(df[col].unique())\n",
    "    unique_values = np.unique(unique_values)\n",
    "    return unique_values\n",
    "\n",
    "def select_highest_agreement_code(df, columns, prefix1, prefix2=None):\n",
    "    \"\"\"\n",
    "    Select the highest agreement code and optionally the second highest agreement code for each item/document,\n",
    "    and assign them to separate columns.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    columns (list): A list of column names representing the annotators.\n",
    "    prefix1 (str): The prefix for the new column name containing the highest agreement code.\n",
    "    prefix2 (str, optional): The prefix for the new column name containing the second highest agreement code.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The updated DataFrame with one or two new columns containing the highest and second highest agreement codes.\n",
    "    \"\"\"\n",
    "    # Group columns by annotator\n",
    "    grouped_columns = group_columns_by_annotator(columns)\n",
    "\n",
    "    # Initialize new column with NaN values\n",
    "    new_column_name1 = f\"{prefix1}_all\"\n",
    "    df[new_column_name1] = pd.Series([np.nan] * df.shape[0], index=df.index)\n",
    "\n",
    "    # Initialize second new column with NaN values if prefix2 is provided\n",
    "    if prefix2 is not None:\n",
    "        new_column_name2 = f\"{prefix2}_all\"\n",
    "        df[new_column_name2] = pd.Series([np.nan] * df.shape[0], index=df.index)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        row_values = []\n",
    "        for annotator_columns in grouped_columns.values():\n",
    "            annotator_values = row[annotator_columns].dropna().unique()\n",
    "            if len(annotator_values) > 0:\n",
    "                row_values.append(annotator_values[0])  # Take the first value for the annotator\n",
    "\n",
    "        if len(row_values) > 1:\n",
    "            # Get the most frequent (highest agreement) code\n",
    "            value_counts = pd.Series(row_values).value_counts()\n",
    "            highest_agreement_code = value_counts.index[0]\n",
    "\n",
    "            # Assign the highest agreement code to the new column\n",
    "            df.at[idx, new_column_name1] = highest_agreement_code\n",
    "\n",
    "            # If prefix2 is provided, assign the second highest agreement code to the second new column\n",
    "            if prefix2 is not None:\n",
    "                second_highest_agreement_code = value_counts.index[1] if len(value_counts.index) > 1 else np.nan\n",
    "                df.at[idx, new_column_name2] = second_highest_agreement_code\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC Fleiss' kappa: 0.4625645019959108\n",
      "DES Fleiss' kappa: 0.446897062460461\n",
      "PV Fleiss' kappa: 0.46375437334466874\n",
      "PS Fleiss' kappa: 0.6145585797463599\n"
     ]
    }
   ],
   "source": [
    "loc_columns = ['LOC_D', 'LOC_S', 'LOC_E', 'LOC_C']\n",
    "des_columns = ['DES1_D', 'DES1_S', 'DES1_E', 'DES1_C','DES2_D', 'DES2_S', 'DES2_E', 'DES2_C']\n",
    "pv_columns = ['PV_D', 'PV_S', 'PV_E', 'PV_C']\n",
    "ps_columns = ['PS_D', 'PS_S', 'PS_E', 'PS_C']\n",
    "\n",
    "loc_kappa = calculate_fleiss_kappa(df,loc_columns)\n",
    "des_kappa = calculate_fleiss_kappa(df,des_columns)\n",
    "ps_kappa = calculate_fleiss_kappa(df,ps_columns)\n",
    "pv_kappa = calculate_fleiss_kappa(df,pv_columns)\n",
    "\n",
    "print(f\"LOC Fleiss' kappa: {loc_kappa}\")\n",
    "print(f\"DES Fleiss' kappa: {des_kappa}\")\n",
    "print(f\"PV Fleiss' kappa: {pv_kappa}\")\n",
    "print(f\"PS Fleiss' kappa: {ps_kappa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code \n",
    "LOC_df = select_highest_agreement_code(df, loc_columns, \"LOC\")\n",
    "PS_df = select_highest_agreement_code(LOC_df, ps_columns, \"PS\")\n",
    "PV_df = select_highest_agreement_code(PS_df, pv_columns, \"PV\")\n",
    "new_df = select_highest_agreement_code(PV_df, des_columns, \"DES1\", \"DES2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC_all</th>\n",
       "      <th>PS_all</th>\n",
       "      <th>PV_all</th>\n",
       "      <th>DES1_all</th>\n",
       "      <th>DES2_all</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Address / Specific Named</td>\n",
       "      <td>Gender, No Race</td>\n",
       "      <td>Gender, No Race</td>\n",
       "      <td>Touch</td>\n",
       "      <td>Reconstructed Scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Address / Specific Named</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>People's Park</td>\n",
       "      <td>Touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radius / Area</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Safety Instructions / Tips</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radius / Area</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Safety Instructions / Tips</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Address / Specific Named</td>\n",
       "      <td>Gender, No Race</td>\n",
       "      <td>No Race, Gender Neutral</td>\n",
       "      <td>Reconstructed Scenario</td>\n",
       "      <td>Memorable detail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    LOC_all           PS_all                   PV_all  \\\n",
       "                                                                        \n",
       "1  Address / Specific Named  Gender, No Race          Gender, No Race   \n",
       "2  Address / Specific Named             none                     none   \n",
       "3             Radius / Area             none                     none   \n",
       "4             Radius / Area             none                     none   \n",
       "5  Address / Specific Named  Gender, No Race  No Race, Gender Neutral   \n",
       "\n",
       "                     DES1_all                DES2_all  \n",
       "                                                       \n",
       "1                      Touch   Reconstructed Scenario  \n",
       "2               People's Park                  Touch   \n",
       "3  Safety Instructions / Tips                     NaN  \n",
       "4  Safety Instructions / Tips                     NaN  \n",
       "5      Reconstructed Scenario        Memorable detail  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = new_df.filter(regex='_all$')\n",
    "new_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
